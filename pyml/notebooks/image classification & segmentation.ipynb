{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_dataset(training_df, image_dir):\n",
    "    \"\"\"\n",
    "    This function takes the training dataframe\n",
    "    and outputs training array and labels\n",
    "    :param training_df: dataframe with ImageId, Target columns\n",
    "    :param image_dir: location of images (folder), string\n",
    "    :return: X, y (training array with features and labels)\n",
    "    \"\"\"\n",
    "    # create empty list to store image vectors\n",
    "    images = []\n",
    "    # create empty list to store targets\n",
    "    targets = []\n",
    "    # loop over the dataframe\n",
    "    for index, row in tqdm(\n",
    "        training_df.iterrows(),\n",
    "        total=len(training_df),\n",
    "        desc=\"processing images\"\n",
    "    ):\n",
    "        # get image id\n",
    "        image_id = row[\"ImageId\"]\n",
    "        # create image path\n",
    "        image_path = os.path.join(image_dir, image_id)\n",
    "        # open image using PIL\n",
    "        image = Image.open(image_path + \".png\")\n",
    "        # resize image to 256x256. we use bilinear resampling\n",
    "        image = image.resize((256, 256), resample=Image.BILINEAR)\n",
    "        # convert image to array\n",
    "        image = np.array(image)\n",
    "        # ravel\n",
    "        image = image.ravel()\n",
    "        # append images and targets lists\n",
    "        images.append(image)\n",
    "        targets.append(int(row[\"target\"]))\n",
    "\n",
    "    # convert list of list of images to numpy array\n",
    "    images = np.array(images)\n",
    "    # print size of this array\n",
    "    print(images.shape)\n",
    "    return images, targets\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"/home/abhishek/workspace/siim_png/train.csv\"\n",
    "    image_path = \"/home/abhishek/workspace/siim_png/train_png/\"\n",
    "    # read CSV with imageid and target columns\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "\n",
    "    # the next step is to randomize the rows of the data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # fetch labels\n",
    "    y = df.target.values\n",
    "\n",
    "    # initiate the kfold class from model_selection module\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # fill the new kfold column\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "        df.loc[v_, 'kfold'] = f\n",
    "        \n",
    "    # we go over the folds created\n",
    "    for fold_ in range(5):\n",
    "        # temporary dataframes for train and test\n",
    "        train_df = df[df.kfold != fold_].reset_index(drop=True)\n",
    "        test_df = df[df.kfold == fold_].reset_index(drop=True)\n",
    "\n",
    "        # create train dataset\n",
    "        # you can move this outside to save some computation time\n",
    "        xtrain, ytrain = create_dataset(train_df, image_path)\n",
    "        # create test dataset\n",
    "        # you can move this outside to save some computation time\n",
    "        xtest, ytest = create_dataset(test_df, image_path)\n",
    "        # fit random forest without any modification of params\n",
    "        clf = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        # predict probability of class 1\n",
    "        preds = clf.predict_proba(xtest)[:, 1]\n",
    "        # print results\n",
    "        print(f\"FOLD: {fold_}\")\n",
    "        print(f\"AUC = {metrics.roc_auc_score(ytest, preds)}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.py\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "# sometimes, you will have images without an ending bit\n",
    "# this takes care of those kind of (corrupt) images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "class ClassificationDataset:\n",
    "\n",
    "    \"\"\"\n",
    "    A general classification dataset class that you can use for all\n",
    "    kinds of image classification problems. For example,\n",
    "    binary classification, multi-class, multi-label classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_paths, targets, resize=None, augmentations=None):\n",
    "        \"\"\"\n",
    "        :param image_paths: list of path to images\n",
    "        :param targets: numpy array\n",
    "        :param resize: tuple, e.g. (256, 256), resizes image if not None\n",
    "        :param augmentations: albumentation augmentations\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.resize = resize\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        For a given \"item\" index, return everything we need\n",
    "        to train a given model\n",
    "        \"\"\"\n",
    "        # use PIL to open the image\n",
    "        image = Image.open(self.image_paths[item])\n",
    "        # convert image to RGB, we have single channel images\n",
    "        image = image.convert(\"RGB\")\n",
    "        # grab correct targets\n",
    "        targets = self.targets[item]\n",
    "        # resize if needed\n",
    "        if self.resize is not None:\n",
    "            image = image.resize(\n",
    "                (self.resize[1], self.resize[0]),\n",
    "                resample=Image.BILINEAR\n",
    "            )\n",
    "        # convert image to numpy array\n",
    "        image = np.array(image)\n",
    "        # if we have albumentation augmentations\n",
    "        # add them to the image\n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        # pytorch expects CHW instead of HWC\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        # return tensors of image and targets\n",
    "        # take a look at the types!\n",
    "        # for regression tasks,\n",
    "        # dtype of targets will change to torch.float\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(data_loader, model, optimizer, device):\n",
    "    \"\"\"\n",
    "    This function does training for one epoch\n",
    "    :param data_loader: this is the pytorch dataloader\n",
    "    :param model: pytorch model\n",
    "    :param optimizer: optimizer, for e.g. adam, sgd, etc\n",
    "    :param device: cuda/cpu\n",
    "    \"\"\"\n",
    "    # put the model in train mode\n",
    "    model.train()\n",
    "    # go over every batch of data in data loader\n",
    "    for data in data_loader:\n",
    "        # remember, we have image and targets\n",
    "        # in our dataset class\n",
    "        inputs = data[\"image\"]\n",
    "        targets = data[\"targets\"]\n",
    "        # move inputs/targets to cuda/cpu device\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "        # zero grad the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # do the forward step of model\n",
    "        outputs = model(inputs)\n",
    "        # calculate loss\n",
    "        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
    "        # backward step the loss\n",
    "        loss.backward()\n",
    "        # step optimizer\n",
    "        optimizer.step()\n",
    "        # if you have a scheduler, you either need to\n",
    "        # step it here or you have to step it after\n",
    "        # the epoch. here, we are not using any learning\n",
    "        # rate scheduler\n",
    "\n",
    "\n",
    "def evaluate(data_loader, model, device):\n",
    "\n",
    "    \"\"\"\n",
    "    This function does evaluation for one epoch\n",
    "    :param data_loader: this is the pytorch dataloader\n",
    "    :param model: pytorch model\n",
    "    :param device: cuda/cpu\n",
    "    \"\"\"\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    # init lists to store targets and outputs\n",
    "    final_targets = []\n",
    "    final_outputs = []\n",
    "    # we use no_grad context\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            inputs = data[\"image\"]\n",
    "            targets = data[\"targets\"]\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            # do the forward step to generate prediction\n",
    "            output = model(inputs)\n",
    "            # convert targets and outputs to lists\n",
    "            targets = targets.detach().cpu().numpy().tolist()\n",
    "            output = output.detach().cpu().numpy().tolist()\n",
    "            # extend the original list\n",
    "            final_targets.extend(targets)\n",
    "            final_outputs.extend(output)\n",
    "    # return final output and final targets\n",
    "    return final_outputs, final_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "import torch.nn as nn\n",
    "import pretrainedmodels\n",
    "\n",
    "\n",
    "def get_model(pretrained):\n",
    "\n",
    "\n",
    "    if pretrained:\n",
    "        model = pretrainedmodels.__dict__[\"alexnet\"](\n",
    "            pretrained='imagenet'\n",
    "        )\n",
    "    else:\n",
    "        model = pretrainedmodels.__dict__[\"alexnet\"](\n",
    "            pretrained=None\n",
    "        )\n",
    "\n",
    "    # print the model here to know whats going on.\n",
    "    model.last_linear = nn.Sequential(\n",
    "        nn.BatchNorm1d(4096),\n",
    "        nn.Dropout(p=0.25),\n",
    "        nn.Linear(in_features=4096, out_features=2048),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(in_features=2048, out_features=1),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dataset\n",
    "import engine\n",
    "from model import get_model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # location of train.csv and train_png folder\n",
    "    # with all the png images\n",
    "    data_path = \"/home/abhishek/workspace/siim_png/\"\n",
    "    # cuda/cpu device\n",
    "    device = \"cuda\"\n",
    "    # let's train for 10 epochs\n",
    "    epochs = 10\n",
    "    # load the dataframe\n",
    "    df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "    # fetch all image ids\n",
    "    images = df.ImageId.values.tolist()\n",
    "    # a list with image locations\n",
    "    images = [\n",
    "        os.path.join(data_path, \"train_png\", i + \".png\") for i in images\n",
    "    ]\n",
    "    # binary targets numpy array\n",
    "    targets = df.target.values\n",
    "    # fetch out model, we will try both pretrained\n",
    "    # and non-pretrained weights\n",
    "    model = get_model(pretrained=True)\n",
    "    # move model to device\n",
    "    model.to(device)\n",
    "    # mean and std values of RGB channels for imagenet dataset\n",
    "    # we use these pre-calculated values when we use weights\n",
    "    # from imagenet.\n",
    "    # when we do not use imagenet weights, we use the mean and\n",
    "    # standard deviation values of the original dataset\n",
    "    # please note that this is a separate calculation\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    # albumentations is an image augmentation library\n",
    "    # that allows you do to many different types of image\n",
    "    # augmentations. here, i am using only normalization\n",
    "    # notice always_apply=True. we always want to apply\n",
    "    # normalization\n",
    "    aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(\n",
    "                mean, std, max_pixel_value=255.0, always_apply=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    # instead of using kfold, i am using train_test_split\n",
    "    # with a fixed random state\n",
    "    train_images, valid_images, train_targets, valid_targets =train_test_split(\n",
    "        images, targets, stratify=targets, random_state=42\n",
    "    )\n",
    "    # fetch the ClassificationDataset class\n",
    "    train_dataset = dataset.ClassificationDataset(\n",
    "        image_paths=train_images,\n",
    "        targets=train_targets,\n",
    "        resize=(227, 227),\n",
    "        augmentations=aug,\n",
    "    )\n",
    "    # torch dataloader creates batches of data\n",
    "    # from classification dataset class\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=16, shuffle=True, num_workers=4\n",
    "    )\n",
    "    # same for validation data\n",
    "    valid_dataset = dataset.ClassificationDataset(\n",
    "        image_paths=valid_images,\n",
    "        targets=valid_targets,\n",
    "        resize=(227, 227),\n",
    "        augmentations=aug,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "    # simple Adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "    # train and print auc score for all epochs\n",
    "    for epoch in range(epochs):\n",
    "        engine.train(train_loader, model, optimizer, device=device)\n",
    "        predictions, valid_targets = engine.evaluate(\n",
    "            valid_loader, model, device=device\n",
    "        )\n",
    "        roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n",
    "        print(\n",
    "            f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet for image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The most popular model used for segmentation tasks is U-Net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_unet.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "\n",
    "    \"\"\"\n",
    "    This function applies two convolutional layers\n",
    "    each followed by a ReLU activation function\n",
    "    :param in_channels: number of input channels\n",
    "    :param out_channels: number of output channels\n",
    "    :return: a down-conv layer\n",
    "    \"\"\"\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "    return conv\n",
    "\n",
    "\n",
    "def crop_tensor(tensor, target_tensor): \n",
    "    \"\"\"\n",
    "    Center crops a tensor to size of a given target tensor size\n",
    "    Please note that this function is applicable only to\n",
    "    this implementation of unet. There are a few assumptions\n",
    "    in this implementation that might not be applicable to all\n",
    "    networks and all other use-cases.\n",
    "    Both tensors are of shape (bs, c, h, w)\n",
    "    :param tensor: a tensor that needs to be cropped\n",
    "    :param target_tensor: target tensor of smaller size\n",
    "    :return: cropped tensor\n",
    "    \"\"\"\n",
    "    target_size = target_tensor.size()[2]\n",
    "    tensor_size = tensor.size()[2]\n",
    "    delta = tensor_size - target_size\n",
    "    delta = delta // 2\n",
    "    return tensor[\n",
    "        :,\n",
    "        :,\n",
    "        delta:tensor_size - delta,\n",
    "        delta:tensor_size - delta\n",
    "    ]\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # we need only one max_pool as it is not learned\n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.down_conv_1 = double_conv(1, 64)\n",
    "        self.down_conv_2 = double_conv(64, 128)\n",
    "        self.down_conv_3 = double_conv(128, 256)\n",
    "        self.down_conv_4 = double_conv(256, 512)\n",
    "        self.down_conv_5 = double_conv(512, 1024)\n",
    "        self.up_trans_1 = nn.ConvTranspose2d(\n",
    "            in_channels=1024,\n",
    "            out_channels=512,\n",
    "            kernel_size=2,\n",
    "            stride=2\n",
    "        )\n",
    "        self.up_conv_1 = double_conv(1024, 512)\n",
    "        self.up_trans_2 = nn.ConvTranspose2d(\n",
    "            in_channels=512,\n",
    "            out_channels=256, \n",
    "            kernel_size=2,\n",
    "            stride=2\n",
    "        )\n",
    "        self.up_conv_2 = double_conv(512, 256)\n",
    "        self.up_trans_3 = nn.ConvTranspose2d(\n",
    "            in_channels=256,\n",
    "            out_channels=128,\n",
    "            kernel_size=2,\n",
    "            stride=2\n",
    "        )\n",
    "        self.up_conv_3 = double_conv(256, 128)\n",
    "        self.up_trans_4 = nn.ConvTranspose2d(\n",
    "            in_channels=128,\n",
    "            out_channels=64,\n",
    "            kernel_size=2,\n",
    "            stride=2\n",
    "        )\n",
    "        self.up_conv_4 = double_conv(128, 64)\n",
    "        self.out = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=2,\n",
    "            kernel_size=1\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, image):\n",
    "\n",
    "        # encoder\n",
    "        x1 = self.down_conv_1(image)\n",
    "        x2 = self.max_pool_2x2(x1)\n",
    "        x3 = self.down_conv_2(x2)\n",
    "        x4 = self.max_pool_2x2(x3)\n",
    "        x5 = self.down_conv_3(x4)\n",
    "        x6 = self.max_pool_2x2(x5)\n",
    "        x7 = self.down_conv_4(x6)\n",
    "        x8 = self.max_pool_2x2(x7)\n",
    "        x9 = self.down_conv_5(x8)\n",
    "        # decoder\n",
    "        x = self.up_trans_1(x9)\n",
    "        y = crop_tensor(x7, x)\n",
    "        x = self.up_conv_1(torch.cat([x, y], axis=1))\n",
    "        x = self.up_trans_2(x)\n",
    "        y = crop_tensor(x5, x)\n",
    "        x = self.up_conv_2(torch.cat([x, y], axis=1))\n",
    "        x = self.up_trans_3(x)\n",
    "        y = crop_tensor(x3, x)\n",
    "        x = self.up_conv_3(torch.cat([x, y], axis=1))\n",
    "        x = self.up_trans_4(x)\n",
    "        y = crop_tensor(x1, x)\n",
    "        x = self.up_conv_4(torch.cat([x, y], axis=1))\n",
    "        # output layer\n",
    "        out = self.out(x)\n",
    "        return out\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    image = torch.rand((1, 1, 572, 572))\n",
    "    model = UNet()\n",
    "    print(model(image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
